{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f26ccd3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-28T08:30:30.843497Z",
     "iopub.status.busy": "2023-05-28T08:30:30.843047Z",
     "iopub.status.idle": "2023-05-28T08:30:32.811846Z",
     "shell.execute_reply": "2023-05-28T08:30:32.810789Z"
    },
    "papermill": {
     "duration": 1.979322,
     "end_time": "2023-05-28T08:30:32.814100",
     "exception": false,
     "start_time": "2023-05-28T08:30:30.834778",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'SSM-s-on-Document-AI-Task'...\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remote: Enumerating objects: 180, done.\u001b[K\r\n",
      "remote: Counting objects:   0% (1/180)\u001b[K\r",
      "remote: Counting objects:   1% (2/180)\u001b[K\r",
      "remote: Counting objects:   2% (4/180)\u001b[K\r",
      "remote: Counting objects:   3% (6/180)\u001b[K\r",
      "remote: Counting objects:   4% (8/180)\u001b[K\r",
      "remote: Counting objects:   5% (9/180)\u001b[K\r",
      "remote: Counting objects:   6% (11/180)\u001b[K\r",
      "remote: Counting objects:   7% (13/180)\u001b[K\r",
      "remote: Counting objects:   8% (15/180)\u001b[K\r",
      "remote: Counting objects:   9% (17/180)\u001b[K\r",
      "remote: Counting objects:  10% (18/180)\u001b[K\r",
      "remote: Counting objects:  11% (20/180)\u001b[K\r",
      "remote: Counting objects:  12% (22/180)\u001b[K\r",
      "remote: Counting objects:  13% (24/180)\u001b[K\r",
      "remote: Counting objects:  14% (26/180)\u001b[K\r",
      "remote: Counting objects:  15% (27/180)\u001b[K\r",
      "remote: Counting objects:  16% (29/180)\u001b[K\r",
      "remote: Counting objects:  17% (31/180)\u001b[K\r",
      "remote: Counting objects:  18% (33/180)\u001b[K\r",
      "remote: Counting objects:  19% (35/180)\u001b[K\r",
      "remote: Counting objects:  20% (36/180)\u001b[K\r",
      "remote: Counting objects:  21% (38/180)\u001b[K\r",
      "remote: Counting objects:  22% (40/180)\u001b[K\r",
      "remote: Counting objects:  23% (42/180)\u001b[K\r",
      "remote: Counting objects:  24% (44/180)\u001b[K\r",
      "remote: Counting objects:  25% (45/180)\u001b[K\r",
      "remote: Counting objects:  26% (47/180)\u001b[K\r",
      "remote: Counting objects:  27% (49/180)\u001b[K\r",
      "remote: Counting objects:  28% (51/180)\u001b[K\r",
      "remote: Counting objects:  29% (53/180)\u001b[K\r",
      "remote: Counting objects:  30% (54/180)\u001b[K\r",
      "remote: Counting objects:  31% (56/180)\u001b[K\r",
      "remote: Counting objects:  32% (58/180)\u001b[K\r",
      "remote: Counting objects:  33% (60/180)\u001b[K\r",
      "remote: Counting objects:  34% (62/180)\u001b[K\r",
      "remote: Counting objects:  35% (63/180)\u001b[K\r",
      "remote: Counting objects:  36% (65/180)\u001b[K\r",
      "remote: Counting objects:  37% (67/180)\u001b[K\r",
      "remote: Counting objects:  38% (69/180)\u001b[K\r",
      "remote: Counting objects:  39% (71/180)\u001b[K\r",
      "remote: Counting objects:  40% (72/180)\u001b[K\r",
      "remote: Counting objects:  41% (74/180)\u001b[K\r",
      "remote: Counting objects:  42% (76/180)\u001b[K\r",
      "remote: Counting objects:  43% (78/180)\u001b[K\r",
      "remote: Counting objects:  44% (80/180)\u001b[K\r",
      "remote: Counting objects:  45% (81/180)\u001b[K\r",
      "remote: Counting objects:  46% (83/180)\u001b[K\r",
      "remote: Counting objects:  47% (85/180)\u001b[K\r",
      "remote: Counting objects:  48% (87/180)\u001b[K\r",
      "remote: Counting objects:  49% (89/180)\u001b[K\r",
      "remote: Counting objects:  50% (90/180)\u001b[K\r",
      "remote: Counting objects:  51% (92/180)\u001b[K\r",
      "remote: Counting objects:  52% (94/180)\u001b[K\r",
      "remote: Counting objects:  53% (96/180)\u001b[K\r",
      "remote: Counting objects:  54% (98/180)\u001b[K\r",
      "remote: Counting objects:  55% (99/180)\u001b[K\r",
      "remote: Counting objects:  56% (101/180)\u001b[K\r",
      "remote: Counting objects:  57% (103/180)\u001b[K\r",
      "remote: Counting objects:  58% (105/180)\u001b[K\r",
      "remote: Counting objects:  59% (107/180)\u001b[K\r",
      "remote: Counting objects:  60% (108/180)\u001b[K\r",
      "remote: Counting objects:  61% (110/180)\u001b[K\r",
      "remote: Counting objects:  62% (112/180)\u001b[K\r",
      "remote: Counting objects:  63% (114/180)\u001b[K\r",
      "remote: Counting objects:  64% (116/180)\u001b[K\r",
      "remote: Counting objects:  65% (117/180)\u001b[K\r",
      "remote: Counting objects:  66% (119/180)\u001b[K\r",
      "remote: Counting objects:  67% (121/180)\u001b[K\r",
      "remote: Counting objects:  68% (123/180)\u001b[K\r",
      "remote: Counting objects:  69% (125/180)\u001b[K\r",
      "remote: Counting objects:  70% (126/180)\u001b[K\r",
      "remote: Counting objects:  71% (128/180)\u001b[K\r",
      "remote: Counting objects:  72% (130/180)\u001b[K\r",
      "remote: Counting objects:  73% (132/180)\u001b[K\r",
      "remote: Counting objects:  74% (134/180)\u001b[K\r",
      "remote: Counting objects:  75% (135/180)\u001b[K\r",
      "remote: Counting objects:  76% (137/180)\u001b[K\r",
      "remote: Counting objects:  77% (139/180)\u001b[K\r",
      "remote: Counting objects:  78% (141/180)\u001b[K\r",
      "remote: Counting objects:  79% (143/180)\u001b[K\r",
      "remote: Counting objects:  80% (144/180)\u001b[K\r",
      "remote: Counting objects:  81% (146/180)\u001b[K\r",
      "remote: Counting objects:  82% (148/180)\u001b[K\r",
      "remote: Counting objects:  83% (150/180)\u001b[K\r",
      "remote: Counting objects:  84% (152/180)\u001b[K\r",
      "remote: Counting objects:  85% (153/180)\u001b[K\r",
      "remote: Counting objects:  86% (155/180)\u001b[K\r",
      "remote: Counting objects:  87% (157/180)\u001b[K\r",
      "remote: Counting objects:  88% (159/180)\u001b[K\r",
      "remote: Counting objects:  89% (161/180)\u001b[K\r",
      "remote: Counting objects:  90% (162/180)\u001b[K\r",
      "remote: Counting objects:  91% (164/180)\u001b[K\r",
      "remote: Counting objects:  92% (166/180)\u001b[K\r",
      "remote: Counting objects:  93% (168/180)\u001b[K\r",
      "remote: Counting objects:  94% (170/180)\u001b[K\r",
      "remote: Counting objects:  95% (171/180)\u001b[K\r",
      "remote: Counting objects:  96% (173/180)\u001b[K\r",
      "remote: Counting objects:  97% (175/180)\u001b[K\r",
      "remote: Counting objects:  98% (177/180)\u001b[K\r",
      "remote: Counting objects:  99% (179/180)\u001b[K\r",
      "remote: Counting objects: 100% (180/180)\u001b[K\r",
      "remote: Counting objects: 100% (180/180), done.\u001b[K\r\n",
      "remote: Compressing objects:   0% (1/133)\u001b[K\r",
      "remote: Compressing objects:   1% (2/133)\u001b[K\r",
      "remote: Compressing objects:   2% (3/133)\u001b[K\r",
      "remote: Compressing objects:   3% (4/133)\u001b[K\r",
      "remote: Compressing objects:   4% (6/133)\u001b[K\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remote: Compressing objects:   5% (7/133)\u001b[K\r",
      "remote: Compressing objects:   6% (8/133)\u001b[K\r",
      "remote: Compressing objects:   7% (10/133)\u001b[K\r",
      "remote: Compressing objects:   8% (11/133)\u001b[K\r",
      "remote: Compressing objects:   9% (12/133)\u001b[K\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remote: Compressing objects:  10% (14/133)\u001b[K\r",
      "remote: Compressing objects:  11% (15/133)\u001b[K\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remote: Compressing objects:  12% (16/133)\u001b[K\r",
      "remote: Compressing objects:  13% (18/133)\u001b[K\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remote: Compressing objects:  14% (19/133)\u001b[K\r",
      "remote: Compressing objects:  15% (20/133)\u001b[K\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remote: Compressing objects:  16% (22/133)\u001b[K\r",
      "remote: Compressing objects:  17% (23/133)\u001b[K\r",
      "remote: Compressing objects:  18% (24/133)\u001b[K\r",
      "remote: Compressing objects:  19% (26/133)\u001b[K\r",
      "remote: Compressing objects:  20% (27/133)\u001b[K\r",
      "remote: Compressing objects:  21% (28/133)\u001b[K\r",
      "remote: Compressing objects:  22% (30/133)\u001b[K\r",
      "remote: Compressing objects:  23% (31/133)\u001b[K\r",
      "remote: Compressing objects:  24% (32/133)\u001b[K\r",
      "remote: Compressing objects:  25% (34/133)\u001b[K\r",
      "remote: Compressing objects:  26% (35/133)\u001b[K\r",
      "remote: Compressing objects:  27% (36/133)\u001b[K\r",
      "remote: Compressing objects:  28% (38/133)\u001b[K\r",
      "remote: Compressing objects:  29% (39/133)\u001b[K\r",
      "remote: Compressing objects:  30% (40/133)\u001b[K\r",
      "remote: Compressing objects:  31% (42/133)\u001b[K\r",
      "remote: Compressing objects:  32% (43/133)\u001b[K\r",
      "remote: Compressing objects:  33% (44/133)\u001b[K\r",
      "remote: Compressing objects:  34% (46/133)\u001b[K\r",
      "remote: Compressing objects:  35% (47/133)\u001b[K\r",
      "remote: Compressing objects:  36% (48/133)\u001b[K\r",
      "remote: Compressing objects:  37% (50/133)\u001b[K\r",
      "remote: Compressing objects:  38% (51/133)\u001b[K\r",
      "remote: Compressing objects:  39% (52/133)\u001b[K\r",
      "remote: Compressing objects:  40% (54/133)\u001b[K\r",
      "remote: Compressing objects:  41% (55/133)\u001b[K\r",
      "remote: Compressing objects:  42% (56/133)\u001b[K\r",
      "remote: Compressing objects:  43% (58/133)\u001b[K\r",
      "remote: Compressing objects:  44% (59/133)\u001b[K\r",
      "remote: Compressing objects:  45% (60/133)\u001b[K\r",
      "remote: Compressing objects:  46% (62/133)\u001b[K\r",
      "remote: Compressing objects:  47% (63/133)\u001b[K\r",
      "remote: Compressing objects:  48% (64/133)\u001b[K\r",
      "remote: Compressing objects:  49% (66/133)\u001b[K\r",
      "remote: Compressing objects:  50% (67/133)\u001b[K\r",
      "remote: Compressing objects:  51% (68/133)\u001b[K\r",
      "remote: Compressing objects:  52% (70/133)\u001b[K\r",
      "remote: Compressing objects:  53% (71/133)\u001b[K\r",
      "remote: Compressing objects:  54% (72/133)\u001b[K\r",
      "remote: Compressing objects:  55% (74/133)\u001b[K\r",
      "remote: Compressing objects:  56% (75/133)\u001b[K\r",
      "remote: Compressing objects:  57% (76/133)\u001b[K\r",
      "remote: Compressing objects:  58% (78/133)\u001b[K\r",
      "remote: Compressing objects:  59% (79/133)\u001b[K\r",
      "remote: Compressing objects:  60% (80/133)\u001b[K\r",
      "remote: Compressing objects:  61% (82/133)\u001b[K\r",
      "remote: Compressing objects:  62% (83/133)\u001b[K\r",
      "remote: Compressing objects:  63% (84/133)\u001b[K\r",
      "remote: Compressing objects:  64% (86/133)\u001b[K\r",
      "remote: Compressing objects:  65% (87/133)\u001b[K\r",
      "remote: Compressing objects:  66% (88/133)\u001b[K\r",
      "remote: Compressing objects:  67% (90/133)\u001b[K\r",
      "remote: Compressing objects:  68% (91/133)\u001b[K\r",
      "remote: Compressing objects:  69% (92/133)\u001b[K\r",
      "remote: Compressing objects:  70% (94/133)\u001b[K\r",
      "remote: Compressing objects:  71% (95/133)\u001b[K\r",
      "remote: Compressing objects:  72% (96/133)\u001b[K\r",
      "remote: Compressing objects:  73% (98/133)\u001b[K\r",
      "remote: Compressing objects:  74% (99/133)\u001b[K\r",
      "remote: Compressing objects:  75% (100/133)\u001b[K\r",
      "remote: Compressing objects:  76% (102/133)\u001b[K\r",
      "remote: Compressing objects:  77% (103/133)\u001b[K\r",
      "remote: Compressing objects:  78% (104/133)\u001b[K\r",
      "remote: Compressing objects:  79% (106/133)\u001b[K\r",
      "remote: Compressing objects:  80% (107/133)\u001b[K\r",
      "remote: Compressing objects:  81% (108/133)\u001b[K\r",
      "remote: Compressing objects:  82% (110/133)\u001b[K\r",
      "remote: Compressing objects:  83% (111/133)\u001b[K\r",
      "remote: Compressing objects:  84% (112/133)\u001b[K\r",
      "remote: Compressing objects:  85% (114/133)\u001b[K\r",
      "remote: Compressing objects:  86% (115/133)\u001b[K\r",
      "remote: Compressing objects:  87% (116/133)\u001b[K\r",
      "remote: Compressing objects:  88% (118/133)\u001b[K\r",
      "remote: Compressing objects:  89% (119/133)\u001b[K\r",
      "remote: Compressing objects:  90% (120/133)\u001b[K\r",
      "remote: Compressing objects:  91% (122/133)\u001b[K\r",
      "remote: Compressing objects:  92% (123/133)\u001b[K\r",
      "remote: Compressing objects:  93% (124/133)\u001b[K\r",
      "remote: Compressing objects:  94% (126/133)\u001b[K\r",
      "remote: Compressing objects:  95% (127/133)\u001b[K\r",
      "remote: Compressing objects:  96% (128/133)\u001b[K\r",
      "remote: Compressing objects:  97% (130/133)\u001b[K\r",
      "remote: Compressing objects:  98% (131/133)\u001b[K\r",
      "remote: Compressing objects:  99% (132/133)\u001b[K\r",
      "remote: Compressing objects: 100% (133/133)\u001b[K\r",
      "remote: Compressing objects: 100% (133/133), done.\u001b[K\r\n",
      "Receiving objects:   0% (1/180)\r",
      "Receiving objects:   1% (2/180)\r",
      "Receiving objects:   2% (4/180)\r",
      "Receiving objects:   3% (6/180)\r",
      "Receiving objects:   4% (8/180)\r",
      "Receiving objects:   5% (9/180)\r",
      "Receiving objects:   6% (11/180)\r",
      "Receiving objects:   7% (13/180)\r",
      "Receiving objects:   8% (15/180)\r",
      "Receiving objects:   9% (17/180)\r",
      "Receiving objects:  10% (18/180)\r",
      "Receiving objects:  11% (20/180)\r",
      "Receiving objects:  12% (22/180)\r",
      "Receiving objects:  13% (24/180)\r",
      "Receiving objects:  14% (26/180)\r",
      "Receiving objects:  15% (27/180)\r",
      "Receiving objects:  16% (29/180)\r",
      "Receiving objects:  17% (31/180)\r",
      "Receiving objects:  18% (33/180)\r",
      "Receiving objects:  19% (35/180)\r",
      "Receiving objects:  20% (36/180)\r",
      "Receiving objects:  21% (38/180)\r",
      "Receiving objects:  22% (40/180)\r",
      "Receiving objects:  23% (42/180)\r",
      "Receiving objects:  24% (44/180)\r",
      "Receiving objects:  25% (45/180)\r",
      "Receiving objects:  26% (47/180)\r",
      "Receiving objects:  27% (49/180)\r",
      "Receiving objects:  28% (51/180)\r",
      "Receiving objects:  29% (53/180)\r",
      "Receiving objects:  30% (54/180)\r",
      "Receiving objects:  31% (56/180)\r",
      "Receiving objects:  32% (58/180)\r",
      "Receiving objects:  33% (60/180)\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Receiving objects:  34% (62/180)\r",
      "Receiving objects:  35% (63/180)\r",
      "Receiving objects:  36% (65/180)\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Receiving objects:  37% (67/180)\r",
      "Receiving objects:  38% (69/180)\r",
      "Receiving objects:  39% (71/180)\r",
      "Receiving objects:  40% (72/180)\r",
      "Receiving objects:  41% (74/180)\r",
      "Receiving objects:  42% (76/180)\r",
      "Receiving objects:  43% (78/180)\r",
      "Receiving objects:  44% (80/180)\r",
      "Receiving objects:  45% (81/180)\r",
      "Receiving objects:  46% (83/180)\r",
      "Receiving objects:  47% (85/180)\r",
      "Receiving objects:  48% (87/180)\r",
      "Receiving objects:  49% (89/180)\r",
      "Receiving objects:  50% (90/180)\r",
      "Receiving objects:  51% (92/180)\r",
      "Receiving objects:  52% (94/180)\r",
      "Receiving objects:  53% (96/180)\r",
      "Receiving objects:  54% (98/180)\r",
      "Receiving objects:  55% (99/180)\r",
      "Receiving objects:  56% (101/180)\r",
      "Receiving objects:  57% (103/180)\r",
      "Receiving objects:  58% (105/180)\r",
      "Receiving objects:  59% (107/180)\r",
      "Receiving objects:  60% (108/180)\r",
      "Receiving objects:  61% (110/180)\r",
      "Receiving objects:  62% (112/180)\r",
      "Receiving objects:  63% (114/180)\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remote: Total 180 (delta 100), reused 81 (delta 29), pack-reused 0\u001b[K\r\n",
      "Receiving objects:  64% (116/180)\r",
      "Receiving objects:  65% (117/180)\r",
      "Receiving objects:  66% (119/180)\r",
      "Receiving objects:  67% (121/180)\r",
      "Receiving objects:  68% (123/180)\r",
      "Receiving objects:  69% (125/180)\r",
      "Receiving objects:  70% (126/180)\r",
      "Receiving objects:  71% (128/180)\r",
      "Receiving objects:  72% (130/180)\r",
      "Receiving objects:  73% (132/180)\r",
      "Receiving objects:  74% (134/180)\r",
      "Receiving objects:  75% (135/180)\r",
      "Receiving objects:  76% (137/180)\r",
      "Receiving objects:  77% (139/180)\r",
      "Receiving objects:  78% (141/180)\r",
      "Receiving objects:  79% (143/180)\r",
      "Receiving objects:  80% (144/180)\r",
      "Receiving objects:  81% (146/180)\r",
      "Receiving objects:  82% (148/180)\r",
      "Receiving objects:  83% (150/180)\r",
      "Receiving objects:  84% (152/180)\r",
      "Receiving objects:  85% (153/180)\r",
      "Receiving objects:  86% (155/180)\r",
      "Receiving objects:  87% (157/180)\r",
      "Receiving objects:  88% (159/180)\r",
      "Receiving objects:  89% (161/180)\r",
      "Receiving objects:  90% (162/180)\r",
      "Receiving objects:  91% (164/180)\r",
      "Receiving objects:  92% (166/180)\r",
      "Receiving objects:  93% (168/180)\r",
      "Receiving objects:  94% (170/180)\r",
      "Receiving objects:  95% (171/180)\r",
      "Receiving objects:  96% (173/180)\r",
      "Receiving objects:  97% (175/180)\r",
      "Receiving objects:  98% (177/180)\r",
      "Receiving objects:  99% (179/180)\r",
      "Receiving objects: 100% (180/180)\r",
      "Receiving objects: 100% (180/180), 345.13 KiB | 2.38 MiB/s, done.\r\n",
      "Resolving deltas:   0% (0/100)\r",
      "Resolving deltas:   1% (1/100)\r",
      "Resolving deltas:   2% (2/100)\r",
      "Resolving deltas:   3% (3/100)\r",
      "Resolving deltas:   4% (4/100)\r",
      "Resolving deltas:   5% (5/100)\r",
      "Resolving deltas:   6% (6/100)\r",
      "Resolving deltas:   7% (7/100)\r",
      "Resolving deltas:   8% (8/100)\r",
      "Resolving deltas:   9% (9/100)\r",
      "Resolving deltas:  10% (10/100)\r",
      "Resolving deltas:  11% (11/100)\r",
      "Resolving deltas:  12% (12/100)\r",
      "Resolving deltas:  13% (13/100)\r",
      "Resolving deltas:  14% (14/100)\r",
      "Resolving deltas:  15% (15/100)\r",
      "Resolving deltas:  16% (16/100)\r",
      "Resolving deltas:  17% (17/100)\r",
      "Resolving deltas:  18% (18/100)\r",
      "Resolving deltas:  19% (19/100)\r",
      "Resolving deltas:  20% (20/100)\r",
      "Resolving deltas:  21% (21/100)\r",
      "Resolving deltas:  22% (22/100)\r",
      "Resolving deltas:  23% (23/100)\r",
      "Resolving deltas:  24% (24/100)\r",
      "Resolving deltas:  25% (25/100)\r",
      "Resolving deltas:  26% (26/100)\r",
      "Resolving deltas:  27% (27/100)\r",
      "Resolving deltas:  28% (28/100)\r",
      "Resolving deltas:  29% (29/100)\r",
      "Resolving deltas:  30% (30/100)\r",
      "Resolving deltas:  31% (31/100)\r",
      "Resolving deltas:  32% (32/100)\r",
      "Resolving deltas:  33% (33/100)\r",
      "Resolving deltas:  34% (34/100)\r",
      "Resolving deltas:  35% (35/100)\r",
      "Resolving deltas:  36% (36/100)\r",
      "Resolving deltas:  37% (37/100)\r",
      "Resolving deltas:  38% (38/100)\r",
      "Resolving deltas:  39% (39/100)\r",
      "Resolving deltas:  40% (40/100)\r",
      "Resolving deltas:  41% (41/100)\r",
      "Resolving deltas:  42% (42/100)\r",
      "Resolving deltas:  43% (43/100)\r",
      "Resolving deltas:  44% (44/100)\r",
      "Resolving deltas:  45% (45/100)\r",
      "Resolving deltas:  46% (46/100)\r",
      "Resolving deltas:  47% (47/100)\r",
      "Resolving deltas:  48% (48/100)\r",
      "Resolving deltas:  49% (49/100)\r",
      "Resolving deltas:  50% (50/100)\r",
      "Resolving deltas:  51% (51/100)\r",
      "Resolving deltas:  52% (52/100)\r",
      "Resolving deltas:  53% (53/100)\r",
      "Resolving deltas:  54% (54/100)\r",
      "Resolving deltas:  55% (55/100)\r",
      "Resolving deltas:  56% (56/100)\r",
      "Resolving deltas:  57% (57/100)\r",
      "Resolving deltas:  58% (58/100)\r",
      "Resolving deltas:  59% (59/100)\r",
      "Resolving deltas:  60% (60/100)\r",
      "Resolving deltas:  61% (61/100)\r",
      "Resolving deltas:  62% (62/100)\r",
      "Resolving deltas:  63% (63/100)\r",
      "Resolving deltas:  64% (64/100)\r",
      "Resolving deltas:  65% (65/100)\r",
      "Resolving deltas:  66% (66/100)\r",
      "Resolving deltas:  67% (67/100)\r",
      "Resolving deltas:  68% (68/100)\r",
      "Resolving deltas:  69% (69/100)\r",
      "Resolving deltas:  70% (70/100)\r",
      "Resolving deltas:  71% (71/100)\r",
      "Resolving deltas:  72% (72/100)\r",
      "Resolving deltas:  73% (73/100)\r",
      "Resolving deltas:  74% (74/100)\r",
      "Resolving deltas:  75% (75/100)\r",
      "Resolving deltas:  76% (76/100)\r",
      "Resolving deltas:  77% (77/100)\r",
      "Resolving deltas:  78% (78/100)\r",
      "Resolving deltas:  79% (79/100)\r",
      "Resolving deltas:  80% (80/100)\r",
      "Resolving deltas:  81% (81/100)\r",
      "Resolving deltas:  82% (82/100)\r",
      "Resolving deltas:  83% (83/100)\r",
      "Resolving deltas:  84% (84/100)\r",
      "Resolving deltas:  85% (85/100)\r",
      "Resolving deltas:  86% (86/100)\r",
      "Resolving deltas:  87% (87/100)\r",
      "Resolving deltas:  88% (88/100)\r",
      "Resolving deltas:  89% (89/100)\r",
      "Resolving deltas:  90% (90/100)\r",
      "Resolving deltas:  91% (91/100)\r",
      "Resolving deltas:  92% (92/100)\r",
      "Resolving deltas:  93% (93/100)\r",
      "Resolving deltas:  94% (94/100)\r",
      "Resolving deltas:  95% (95/100)\r",
      "Resolving deltas:  96% (96/100)\r",
      "Resolving deltas:  97% (97/100)\r",
      "Resolving deltas:  98% (98/100)\r",
      "Resolving deltas:  99% (99/100)\r",
      "Resolving deltas: 100% (100/100)\r",
      "Resolving deltas: 100% (100/100), done.\r\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/uakarsh/SSM-s-on-Document-AI-Task.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13eb0495",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-28T08:30:32.830229Z",
     "iopub.status.busy": "2023-05-28T08:30:32.829927Z",
     "iopub.status.idle": "2023-05-28T08:31:15.193250Z",
     "shell.execute_reply": "2023-05-28T08:31:15.192130Z"
    },
    "papermill": {
     "duration": 42.374294,
     "end_time": "2023-05-28T08:31:15.195858",
     "exception": false,
     "start_time": "2023-05-28T08:30:32.821564",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.12.0)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting accelerate\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Downloading accelerate-0.19.0-py3-none-any.whl (219 kB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/219.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m219.1/219.1 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate) (1.23.5)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (21.3)\r\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\r\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.4.1)\r\n",
      "Requirement already satisfied: torch>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.0.0)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate) (3.0.9)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->accelerate) (3.12.0)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->accelerate) (4.5.0)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->accelerate) (1.12)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->accelerate) (3.1)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->accelerate) (3.1.2)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.6.0->accelerate) (2.1.2)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.6.0->accelerate) (1.3.0)\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing collected packages: accelerate\r\n",
      "  Attempting uninstall: accelerate\r\n",
      "    Found existing installation: accelerate 0.12.0\r\n",
      "    Uninstalling accelerate-0.12.0:\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Successfully uninstalled accelerate-0.12.0\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully installed accelerate-0.19.0\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip -qqq install -r /kaggle/input/docvqa-hf-dataset/LayoutLMv3-DocVQA/requirements.txt\n",
    "!pip -qqq install -r /kaggle/working/SSM-s-on-Document-AI-Task/requirements.txt\n",
    "!pip install -U accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "065b690e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-28T08:31:15.214207Z",
     "iopub.status.busy": "2023-05-28T08:31:15.213880Z",
     "iopub.status.idle": "2023-05-28T08:31:19.830345Z",
     "shell.execute_reply": "2023-05-28T08:31:19.829109Z"
    },
    "papermill": {
     "duration": 4.628401,
     "end_time": "2023-05-28T08:31:19.832860",
     "exception": false,
     "start_time": "2023-05-28T08:31:15.204459",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cp -r /kaggle/input/docvqa-hf-dataset/LayoutLMv3-DocVQA/docvqa_cached_extractive_all_lowercase_True_msr_False_extraction_v3_enumeration ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "544893eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-28T08:31:19.852938Z",
     "iopub.status.busy": "2023-05-28T08:31:19.852604Z",
     "iopub.status.idle": "2023-05-28T08:31:22.664654Z",
     "shell.execute_reply": "2023-05-28T08:31:22.663670Z"
    },
    "papermill": {
     "duration": 2.824152,
     "end_time": "2023-05-28T08:31:22.666908",
     "exception": false,
     "start_time": "2023-05-28T08:31:19.842756",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Logging into wandb\n",
    "\n",
    "import wandb\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "user_secrets = UserSecretsClient()\n",
    "secret_value_0 = user_secrets.get_secret(\"wandb_api\")\n",
    "wandb.login(key=secret_value_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "840c6bbb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-28T08:31:22.685526Z",
     "iopub.status.busy": "2023-05-28T08:31:22.684454Z",
     "iopub.status.idle": "2023-05-28T08:31:22.690004Z",
     "shell.execute_reply": "2023-05-28T08:31:22.689165Z"
    },
    "papermill": {
     "duration": 0.016984,
     "end_time": "2023-05-28T08:31:22.692196",
     "exception": false,
     "start_time": "2023-05-28T08:31:22.675212",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/kaggle/working/SSM-s-on-Document-AI-Task/src\")\n",
    "sys.path.append(\"/kaggle/input/docvqa-hf-dataset/LayoutLMv3-DocVQA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb157ee9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-28T08:31:22.709505Z",
     "iopub.status.busy": "2023-05-28T08:31:22.709216Z",
     "iopub.status.idle": "2023-05-28T08:31:37.403913Z",
     "shell.execute_reply": "2023-05-28T08:31:37.402823Z"
    },
    "papermill": {
     "duration": 14.707085,
     "end_time": "2023-05-28T08:31:37.407410",
     "exception": false,
     "start_time": "2023-05-28T08:31:22.700325",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoTokenizer, AutoFeatureExtractor, AutoModelForQuestionAnswering, AutoConfig\n",
    "\n",
    "from datasets import load_from_disk, DatasetDict\n",
    "\n",
    "from src.utils import get_optimizers, create_and_fill_np_array, write_data, anls_metric_str, postprocess_qa_predictions\n",
    "from src.data.tokenization import tokenize_docvqa, DocVQACollator\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.loggers import WandbLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f11e5863",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-28T08:31:37.430172Z",
     "iopub.status.busy": "2023-05-28T08:31:37.429570Z",
     "iopub.status.idle": "2023-05-28T08:31:37.440632Z",
     "shell.execute_reply": "2023-05-28T08:31:37.439676Z"
    },
    "papermill": {
     "duration": 0.022581,
     "end_time": "2023-05-28T08:31:37.442750",
     "exception": false,
     "start_time": "2023-05-28T08:31:37.420169",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pl.seed_everything(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0445d68c",
   "metadata": {
    "papermill": {
     "duration": 0.008303,
     "end_time": "2023-05-28T08:31:37.459388",
     "exception": false,
     "start_time": "2023-05-28T08:31:37.451085",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1. All hyperparameters setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a577e27",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-28T08:31:37.477345Z",
     "iopub.status.busy": "2023-05-28T08:31:37.477075Z",
     "iopub.status.idle": "2023-05-28T08:31:37.490983Z",
     "shell.execute_reply": "2023-05-28T08:31:37.490172Z"
    },
    "papermill": {
     "duration": 0.025414,
     "end_time": "2023-05-28T08:31:37.493183",
     "exception": false,
     "start_time": "2023-05-28T08:31:37.467769",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "dataset_file = \"/kaggle/working/docvqa_cached_extractive_all_lowercase_True_msr_False_extraction_v3_enumeration\"\n",
    "batch_size = 4\n",
    "learning_rate = 2e-5\n",
    "num_epochs = 5\n",
    "seed = 42\n",
    "pretrained_model_name = 'microsoft/layoutlmv3-base'\n",
    "use_generation = False\n",
    "stride = 0\n",
    "ignore_unmatched_span = 1\n",
    "extraction_nbest = 20\n",
    "max_answer_length = 100\n",
    "\n",
    "image_dir = {\"train\": \"/kaggle/input/docvqa-dataset/train/train\", \"val\": \"/kaggle/input/docvqa-dataset/val/val\", \"test\": \"/kaggle/input/docvqa-dataset/test/test\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a53391e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-28T08:31:37.511731Z",
     "iopub.status.busy": "2023-05-28T08:31:37.510788Z",
     "iopub.status.idle": "2023-05-28T08:31:42.998349Z",
     "shell.execute_reply": "2023-05-28T08:31:42.997237Z"
    },
    "papermill": {
     "duration": 5.499104,
     "end_time": "2023-05-28T08:31:43.000651",
     "exception": false,
     "start_time": "2023-05-28T08:31:37.501547",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e37bc17e4ccb4a4d99e3cd8aa9583d3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/1.14k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8678a28d715149f28b2c15380c9b6505",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5a83e04dc044e91bfd87fb603160887",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a825302957be40f98d61f26248ee7554",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)rocessor_config.json:   0%|          | 0.00/275 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/models/layoutlmv3/feature_extraction_layoutlmv3.py:30: FutureWarning: The class LayoutLMv3FeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use LayoutLMv3ImageProcessor instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f916a50eb2c142beb0a7cac5b36b91f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/856 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "365dfa0393e74278b800a592d83267d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/501M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LayoutLMv3ForQuestionAnswering were not initialized from the model checkpoint at microsoft/layoutlmv3-base and are newly initialized: ['qa_outputs.out_proj.bias', 'qa_outputs.dense.bias', 'qa_outputs.out_proj.weight', 'qa_outputs.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name, use_fast=True)\n",
    "feature_extractor = AutoFeatureExtractor.from_pretrained(pretrained_model_name, apply_ocr=False)\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(pretrained_model_name)\n",
    "config = AutoConfig.from_pretrained(pretrained_model_name)\n",
    "config.update({\"learning_rate\" : learning_rate, \"batch_size\" : batch_size})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d38bd15",
   "metadata": {
    "papermill": {
     "duration": 0.009899,
     "end_time": "2023-05-28T08:31:43.020546",
     "exception": false,
     "start_time": "2023-05-28T08:31:43.010647",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2. Pre-processing steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4015c686",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-28T08:31:43.040660Z",
     "iopub.status.busy": "2023-05-28T08:31:43.040348Z",
     "iopub.status.idle": "2023-05-28T08:31:43.066627Z",
     "shell.execute_reply": "2023-05-28T08:31:43.065784Z"
    },
    "papermill": {
     "duration": 0.038662,
     "end_time": "2023-05-28T08:31:43.068637",
     "exception": false,
     "start_time": "2023-05-28T08:31:43.029975",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "collator = DocVQACollator(tokenizer, feature_extractor, pretrained_model_name=pretrained_model_name, model=model)\n",
    "dataset = load_from_disk(dataset_file)\n",
    "# dataset = DatasetDict({\"train\": dataset[\"train\"].select(range(10)), \"val\": dataset['val'].select(range(10)), \"test\": dataset['test'].select(range(10))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc137999",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-05-28T08:31:43.089565Z",
     "iopub.status.busy": "2023-05-28T08:31:43.088794Z",
     "iopub.status.idle": "2023-05-28T08:57:13.775850Z",
     "shell.execute_reply": "2023-05-28T08:57:13.774716Z"
    },
    "papermill": {
     "duration": 1530.701811,
     "end_time": "2023-05-28T08:57:13.779874",
     "exception": false,
     "start_time": "2023-05-28T08:31:43.078063",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "418aee408e7c4609a72ba1623f8dd53f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#1:   0%|          | 0/1234 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2c755e1f31c4a14ab562fc40eec27cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#0:   0%|          | 0/1234 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6946b5f072448d98038db06e4e247a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#2:   0%|          | 0/1234 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22b6860cad594396b22abe3e4ed0bb1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#3:   0%|          | 0/1234 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e94fb8e0685e4666b9e92abb814d050a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#4:   0%|          | 0/1234 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99c5c4e52d774fc4973e87c58aa27a21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#5:   0%|          | 0/1234 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e3a993120c04f288337b4b127c6ffe5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#6:   0%|          | 0/1234 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4542ed1d29984517a40e72f93edfe65e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#7:   0%|          | 0/1233 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed61f7df10bf448284c48a0d74fb8027",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#0:   0%|          | 0/168 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3a9b4f02f9a4fecb62f569221c80fda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#1:   0%|          | 0/168 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02405f9b61254f53ae4609a6b67c16db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#2:   0%|          | 0/168 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f0dbcf2f0b34f2c92f184ab17dad8b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#3:   0%|          | 0/168 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a9d5d0fe6c44f64a5716aae9a38e975",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#4:   0%|          | 0/168 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33d16ebffe8745a582841e279ee94847",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#5:   0%|          | 0/167 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72671ee54c824a75a89727338f7ac86b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#6:   0%|          | 0/167 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d39f28a034234453a6dee2dbf2626b6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#7:   0%|          | 0/167 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76932906655b4ca0beae3f59c231c242",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#0:   0%|          | 0/163 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "155ee0ee1663458597c13116d90a95d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#1:   0%|          | 0/163 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "482e2384c4fe48e0997d797d9c1f7bee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#2:   0%|          | 0/163 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f198d43e3cab4d9a800157c247dd5d3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#4:   0%|          | 0/162 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a0b29fee1194be38a4ffc0996714bb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#3:   0%|          | 0/163 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf12b3fd59764d0198b64dce71d1d006",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#5:   0%|          | 0/162 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb02ae0b55074a619d7a959bd7fcfebb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#6:   0%|          | 0/162 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fac854d2dc2c4526b83de375a2f8f9e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#7:   0%|          | 0/162 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "use_msr = \"msr_True\" in dataset_file\n",
    "tokenized = dataset.map(tokenize_docvqa,\n",
    "                            fn_kwargs={\"tokenizer\": tokenizer,\n",
    "                                       \"img_dir\": image_dir,\n",
    "                                       \"use_msr_ocr\": use_msr,\n",
    "                                       \"use_generation\": bool(use_generation),\n",
    "                                       \"doc_stride\": stride,\n",
    "                                       \"ignore_unmatched_answer_span_during_train\": bool(ignore_unmatched_span)},\n",
    "                            batched=True, num_proc=8,batch_size = 4,\n",
    "                            load_from_cache_file=True,\n",
    "                            remove_columns=dataset[\"val\"].column_names\n",
    "                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81499e2a",
   "metadata": {
    "papermill": {
     "duration": 0.016207,
     "end_time": "2023-05-28T08:57:13.813178",
     "exception": false,
     "start_time": "2023-05-28T08:57:13.796971",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3. Writing some post-processing steps and defining DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "40a31dde",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-28T08:57:13.847562Z",
     "iopub.status.busy": "2023-05-28T08:57:13.847185Z",
     "iopub.status.idle": "2023-05-28T08:57:13.853994Z",
     "shell.execute_reply": "2023-05-28T08:57:13.853121Z"
    },
    "papermill": {
     "duration": 0.0264,
     "end_time": "2023-05-28T08:57:13.855918",
     "exception": false,
     "start_time": "2023-05-28T08:57:13.829518",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DataModule(pl.LightningDataModule):\n",
    "  def __init__(self, batch_size:int = 8):\n",
    "    super(DataModule, self).__init__()\n",
    "    self.batch_size = batch_size\n",
    "\n",
    "  def train_dataloader(self):\n",
    "    return DataLoader(tokenized[\"train\"].remove_columns(\"metadata\"), batch_size = self.batch_size,\n",
    "                      shuffle = True, pin_memory=True, collate_fn=collator)\n",
    "    \n",
    "  def val_dataloader(self):\n",
    "    return DataLoader(tokenized[\"val\"].remove_columns(\"metadata\"), batch_size = self.batch_size,\n",
    "                      shuffle = False, collate_fn=collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "19d0bc64",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-28T08:57:13.889901Z",
     "iopub.status.busy": "2023-05-28T08:57:13.889628Z",
     "iopub.status.idle": "2023-05-28T08:57:13.894736Z",
     "shell.execute_reply": "2023-05-28T08:57:13.893941Z"
    },
    "papermill": {
     "duration": 0.024316,
     "end_time": "2023-05-28T08:57:13.896599",
     "exception": false,
     "start_time": "2023-05-28T08:57:13.872283",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pl_dl = DataModule()\n",
    "# sample = next(iter(pl_dl.train_dataloader()))\n",
    "\n",
    "# for key in sample:\n",
    "#     sample[key] = sample[key].to(device)\n",
    "# model = model.to(device)\n",
    "# output = model(**sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84bca9fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-28T08:57:13.930419Z",
     "iopub.status.busy": "2023-05-28T08:57:13.930145Z",
     "iopub.status.idle": "2023-05-28T08:57:14.050854Z",
     "shell.execute_reply": "2023-05-28T08:57:14.049921Z"
    },
    "papermill": {
     "duration": 0.140455,
     "end_time": "2023-05-28T08:57:14.053352",
     "exception": false,
     "start_time": "2023-05-28T08:57:13.912897",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "t_total = int(len(pl_dl.train_dataloader()) * num_epochs)\n",
    "# optimizer, scheduler = get_optimizers(model=model, learning_rate=learning_rate, num_training_steps=t_total,\n",
    "#                                           warmup_step=0, eps=1e-8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4d0f87",
   "metadata": {
    "papermill": {
     "duration": 0.016547,
     "end_time": "2023-05-28T08:57:14.086762",
     "exception": false,
     "start_time": "2023-05-28T08:57:14.070215",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 4. Defining the Modeling approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a49e00c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-28T08:57:14.121492Z",
     "iopub.status.busy": "2023-05-28T08:57:14.121121Z",
     "iopub.status.idle": "2023-05-28T08:57:14.137887Z",
     "shell.execute_reply": "2023-05-28T08:57:14.136861Z"
    },
    "papermill": {
     "duration": 0.036995,
     "end_time": "2023-05-28T08:57:14.140207",
     "exception": false,
     "start_time": "2023-05-28T08:57:14.103212",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class S4Model(pl.LightningModule):\n",
    "\n",
    "  def __init__(self, config, use_pretrained_word_embedding = True):\n",
    "\n",
    "    super(S4Model, self).__init__()\n",
    "    self.save_hyperparameters()\n",
    "    \n",
    "    self.model = AutoModelForQuestionAnswering.from_config(config)\n",
    "    if use_pretrained_word_embedding:\n",
    "        \n",
    "        ## Currently working only for LayoutLMv3\n",
    "        from transformers import AutoModel\n",
    "        layoutlm_dummy = AutoModel.from_pretrained(config._name_or_path)\n",
    "        self.model.layoutlmv3.embeddings.word_embeddings = nn.Embedding.from_pretrained(layoutlm_dummy.embeddings.word_embeddings.weight)\n",
    "        print(f\"The word embedding has been initialized from : {config._name_or_path}\")\n",
    "    \n",
    "    self.learning_rate = config.learning_rate\n",
    "  \n",
    "  def forward(self, batch):\n",
    "    return self.model(**batch)\n",
    "\n",
    "  def setup_optimizer(self, weight_decay = 0.01):\n",
    "    \"\"\"\n",
    "    S4 requires a specific optimizer setup.\n",
    "\n",
    "    The S4 layer (A, B, C, dt) parameters typically\n",
    "    require a smaller learning rate (typically 0.001), with no weight decay.\n",
    "\n",
    "    The rest of the model can be trained with a higher learning rate (e.g. 0.004, 0.01)\n",
    "    and weight decay (if desired).\n",
    "    \"\"\"\n",
    "\n",
    "    # All parameters in the model\n",
    "    all_parameters = list(self.model.parameters())\n",
    "\n",
    "    # General parameters don't contain the special _optim key\n",
    "    params = [p for p in all_parameters if not hasattr(p, \"_optim\")]\n",
    "\n",
    "    # Create an optimizer with the general parameters\n",
    "    optimizer = AdamW(params, lr=self.lr, weight_decay=weight_decay)\n",
    "\n",
    "    # Add parameters with special hyperparameters\n",
    "    hps = [getattr(p, \"_optim\") for p in all_parameters if hasattr(p, \"_optim\")]\n",
    "    hps = [\n",
    "        dict(s) for s in sorted(list(dict.fromkeys(frozenset(hp.items()) for hp in hps)))\n",
    "    ]  # Unique dicts\n",
    "    for hp in hps:\n",
    "        params = [p for p in all_parameters if getattr(p, \"_optim\", None) == hp]\n",
    "        optimizer.add_param_group(\n",
    "            {\"params\": params, **hp}\n",
    "        )\n",
    "\n",
    "    # Create a lr scheduler\n",
    "    # scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=patience, factor=0.2)\n",
    "    # scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs)\n",
    "\n",
    "    # Print optimizer info\n",
    "    keys = sorted(set([k for hp in hps for k in hp.keys()]))\n",
    "    for i, g in enumerate(optimizer.param_groups):\n",
    "        group_hps = {k: g.get(k, None) for k in keys}\n",
    "        print(' | '.join([\n",
    "            f\"Optimizer group {i}\",\n",
    "            f\"{len(g['params'])} tensors\",\n",
    "        ] + [f\"{k} {v}\" for k, v in group_hps.items()]))\n",
    "\n",
    "    return optimizer# , scheduler\n",
    "\n",
    "  def configure_optimizers(self):\n",
    "    optimizer, scheduler = get_optimizers(model=self.model, learning_rate=self.learning_rate, num_training_steps=t_total,\n",
    "                                          warmup_step=0, eps=1e-8)\n",
    "    return optimizer\n",
    "    \n",
    "\n",
    "  def training_step(self, batch, batch_idx):\n",
    "\n",
    "    ## Forward Propagatipn\n",
    "    outputs = self(batch)\n",
    "    self.log(\"train_loss\", outputs.loss.item(), prog_bar = True, on_epoch = True, on_step = True)\n",
    "\n",
    "    ## Backpropagation\n",
    "    loss = outputs.loss\n",
    "    return loss\n",
    "\n",
    "  def validation_step(self, batch, batch_idx):\n",
    "    outputs = self(batch)\n",
    "    self.log(\"val_loss\", outputs.loss.item(), prog_bar = True, on_epoch = True, on_step = True)\n",
    "\n",
    "    loss = outputs.loss\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e00e6a",
   "metadata": {
    "papermill": {
     "duration": 0.016245,
     "end_time": "2023-05-28T08:57:14.173077",
     "exception": false,
     "start_time": "2023-05-28T08:57:14.156832",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 5. Train and Go!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8694107c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-28T08:57:14.208135Z",
     "iopub.status.busy": "2023-05-28T08:57:14.207783Z",
     "iopub.status.idle": "2023-05-28T08:57:14.215065Z",
     "shell.execute_reply": "2023-05-28T08:57:14.214073Z"
    },
    "papermill": {
     "duration": 0.027275,
     "end_time": "2023-05-28T08:57:14.217165",
     "exception": false,
     "start_time": "2023-05-28T08:57:14.189890",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def main(config):\n",
    "    \n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        dirpath=\"./s4d/models\", monitor=\"val_loss_epoch\", mode=\"min\", filename = 's4d_best_ckpt'\n",
    "    )\n",
    "    \n",
    "    wandb.init(project=\"Benchmarking LayoutLMv3 on DocVQA\")\n",
    "    wandb_logger = WandbLogger(project=\"Benchmarking LayoutLMv3 on DocVQA\", entity=\"iakarshu\", run = \"first_run\")\n",
    "    \n",
    "    max_epochs = 5\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs = max_epochs,\n",
    "        default_root_dir=\"./s4d/logs\",\n",
    "        accelerator=\"auto\", \n",
    "        devices=\"auto\",\n",
    "        logger=wandb_logger,\n",
    "        callbacks=[checkpoint_callback],\n",
    "        # deterministic=True\n",
    "    )\n",
    "    \n",
    "    pl_model = S4Model(config)\n",
    "    pl_dl = DataModule(batch_size = config.batch_size)\n",
    "    \n",
    "    trainer.fit(pl_model, pl_dl)\n",
    "\n",
    "    return pl_model, pl_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4ff3cd3f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-28T08:57:14.251825Z",
     "iopub.status.busy": "2023-05-28T08:57:14.251546Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": false,
     "start_time": "2023-05-28T08:57:14.233749",
     "status": "running"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33miakarshu\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20230528_085714-ah9kr9nd\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mplayful-surf-4\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/iakarshu/Benchmarking%20LayoutLMv3%20on%20DocVQA\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/iakarshu/Benchmarking%20LayoutLMv3%20on%20DocVQA/runs/ah9kr9nd\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loggers/wandb.py:395: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The word embedding has been initialized from : microsoft/layoutlmv3-base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "231c9f75298c47799cd8c45bc9edd0ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a LayoutLMv3TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/modeling_utils.py:866: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0155a0bbc4da4b728a1d5097d4af73cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "122401c635da4d6fa57ec1b26d0bafa6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f94ccff60e06452eb12d67887d0aaddc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06e1cf5bda8847e99893293d6896ea13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "  pl_model, pl_dl = main(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c71e06e",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-05-28T08:25:34.349430Z",
     "iopub.status.idle": "2023-05-28T08:25:34.350171Z",
     "shell.execute_reply": "2023-05-28T08:25:34.349949Z",
     "shell.execute_reply.started": "2023-05-28T08:25:34.349926Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def evaluate(args, tokenizer, valid_dataloader, model,\n",
    "#              valid_dataset_before_tokenized: Dataset, metadata,\n",
    "#              res_file=None, err_file=None):\n",
    "#     model.eval()\n",
    "#     all_start_logits = []\n",
    "#     all_end_logits = []\n",
    "#     with torch.no_grad(), torch.cuda.amp.autocast(enabled=bool(args.fp16)):\n",
    "#         for index, batch in tqdm(enumerate(valid_dataloader), desc=\"--validation\", total=len(valid_dataloader)):\n",
    "#             batch.start_positions = None\n",
    "#             batch.end_positions = None\n",
    "#             outputs = model(**batch)\n",
    "#             start_logits = outputs.start_logits\n",
    "#             end_logits = outputs.end_logits\n",
    "#             start_logits = accelerator.pad_across_processes(start_logits, dim=1, pad_index=-100)\n",
    "#             end_logits = accelerator.pad_across_processes(end_logits, dim=1, pad_index=-100)\n",
    "#             all_start_logits.append(accelerator.gather_for_metrics(start_logits).cpu().numpy())\n",
    "#             all_end_logits.append(accelerator.gather_for_metrics(end_logits).cpu().numpy())\n",
    "\n",
    "#     max_len = max([x.shape[1] for x in all_start_logits])  # Get the max_length of the tensor\n",
    "#     eval_dataset = valid_dataloader.dataset\n",
    "#     # concatenate the numpy array\n",
    "#     start_logits_concat = create_and_fill_np_array(all_start_logits, eval_dataset, max_len)\n",
    "#     end_logits_concat = create_and_fill_np_array(all_end_logits, eval_dataset, max_len)\n",
    "#     # delete the list of numpy arrays\n",
    "#     del all_start_logits\n",
    "#     del all_end_logits\n",
    "\n",
    "#     outputs_numpy = (start_logits_concat, end_logits_concat)\n",
    "#     prediction_dict, prediction_list = postprocess_qa_predictions(dataset_before_tokenized = valid_dataset_before_tokenized,\n",
    "#                                                                       metadata=metadata, predictions=outputs_numpy,\n",
    "#                                                                       n_best_size=args.extraction_nbest, max_answer_length=args.max_answer_length)\n",
    "#     all_pred_texts = [prediction['answer'] for prediction in prediction_list]\n",
    "#     truth = [data[\"original_answer\"] for data in valid_dataset_before_tokenized]\n",
    "#     accelerator.print(f\"prediction: {all_pred_texts[:10]}\")\n",
    "#     accelerator.print(f\"gold_answers: {truth[:10]}\")\n",
    "#     all_anls, anls = anls_metric_str(predictions=all_pred_texts, gold_labels=truth)\n",
    "#     accelerator.print(f\"[Info] Average Normalized Lev.S : {anls} \", flush=True)\n",
    "#     if res_file is not None and accelerator.is_main_process:\n",
    "#         accelerator.print(f\"Writing results to {res_file} and {err_file}\")\n",
    "#         write_data(data=prediction_list, file=res_file)\n",
    "#     return anls"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "papermill": {
   "default_parameters": {},
   "duration": null,
   "end_time": null,
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-05-28T08:30:20.169053",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}